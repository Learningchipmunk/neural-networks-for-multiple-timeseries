## Training and environment variables
EPOCHS = 10
PADDING_VALUE = -1
LR = 1e-4
add_padding=True
batch_size = 1
max_seq_len = 6000
conf_path = 'Configs/retnet-small-6gbvram/config.json'
save_path="Results/Small_BiRetNet_MultipleSegs/" #_MSEonly
save_best_model=True 
load_model_from_path=True
early_stopping_patience=3

# Model params
input_dim = len(numeraidata.feature_cols)
output_dim = len(numeraidata.target_names)
embed_dropout_rate=0.2
is_multiple_segments_input=True
is_bidir=True
max_num_era_in_seq = int(np.ceil(max_seq_len / np.min([train_df.groupby('era_int').era_int.count().min(), val_df.groupby('era_int').era_int.count().min(), test_df.groupby('era_int').era_int.count().min()]))) + 1#+1 because of the sliding window, it takes into account the case where we end an era and we begin one in the same sequence

# Loss params
lambda_mse  = 1.0
lambda_corr = 1.0

# Uses device available (GPU or CPU)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
device